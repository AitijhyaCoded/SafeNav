{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is inserted to fix the issue with long routes failing due to API limits and timeouts.\n",
    "# We will implement caching for weather data and optimize the Dijkstra algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583b1f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\raiti\\.cache\\kagglehub\\datasets\\aditya2803\\india-floods-inventory\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"aditya2803/india-floods-inventory\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b43aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India_Floods_Inventory.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acb38826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    UEI  Start Date    End Date Duration(Days)   Main Cause  \\\n",
      "0  UEI-IMD-FL-2015-0001  2015-06-20  2015-06-21              1  Heavy rains   \n",
      "1  UEI-IMD-FL-2015-0002  2015-11-15  2015-11-23              8  Heavy rains   \n",
      "2  UEI-IMD-FL-2015-0003  2015-12-22  2015-12-22              0  Heavy rains   \n",
      "3  UEI-IMD-FL-2015-0004  2015-10-06  2015-10-06              0  Heavy rains   \n",
      "4  UEI-IMD-FL-2015-0005  2015-02-19  2015-02-19              0  Heavy rains   \n",
      "\n",
      "  Location                                          Districts  \\\n",
      "0      NaN  East Godavari, Srikakulam, Visakhapatnam and W...   \n",
      "1      NaN  Anantapur, Chittoor, East Godavari, Krishna, N...   \n",
      "2      NaN                                     Vishakhapatnam   \n",
      "3      NaN                         Parts of Arunachal Pradesh   \n",
      "4      NaN                                     Parts of Assam   \n",
      "\n",
      "               State  Latitude  Longitude  Severity  Area Affected  \\\n",
      "0    ANDHRA  PRADESH       NaN        NaN       NaN            NaN   \n",
      "1    ANDHRA  PRADESH       NaN        NaN       NaN            NaN   \n",
      "2    ANDHRA  PRADESH       NaN        NaN       NaN            NaN   \n",
      "3  ARUNACHAL PRADESH       NaN        NaN       NaN            NaN   \n",
      "4              ASSAM       NaN        NaN       NaN            NaN   \n",
      "\n",
      "   Human fatality  Human injured  Human Displaced  Animal Fatality  \\\n",
      "0             NaN            NaN              NaN              NaN   \n",
      "1            88.0            NaN              NaN          16710.0   \n",
      "2             4.0            NaN              NaN              NaN   \n",
      "3             2.0            NaN              NaN              NaN   \n",
      "4             2.0            NaN              NaN              NaN   \n",
      "\n",
      "                   Description of Casualties/injured  \\\n",
      "0                                                NaN   \n",
      "1  88 persons died. 16710 animals perished. (844 ...   \n",
      "2                    4 persons died due to landslips   \n",
      "3                                    2 persons died.   \n",
      "4                    2 persons died due to landslide   \n",
      "\n",
      "                                   Extent of damage  Event Source  \\\n",
      "0  i) Damage to 2000 hectares of crops reported. ...          IMD   \n",
      "1  i) Extensive damage to Agricultural crops (mor...          IMD   \n",
      "2                                         Landslips           IMD   \n",
      "3                                                NaN          IMD   \n",
      "4                                                NaN          IMD   \n",
      "\n",
      "  Event Souce ID  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"{path}/India_Floods_Inventory.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd77b078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Latitude  Longitude  Start Date   Main Cause  Area Affected  Severity  \\\n",
      "0       NaN        NaN  2015-06-20  Heavy rains            NaN       NaN   \n",
      "1       NaN        NaN  2015-11-15  Heavy rains            NaN       NaN   \n",
      "2       NaN        NaN  2015-12-22  Heavy rains            NaN       NaN   \n",
      "3       NaN        NaN  2015-10-06  Heavy rains            NaN       NaN   \n",
      "4       NaN        NaN  2015-02-19  Heavy rains            NaN       NaN   \n",
      "\n",
      "               State  \n",
      "0    ANDHRA  PRADESH  \n",
      "1    ANDHRA  PRADESH  \n",
      "2    ANDHRA  PRADESH  \n",
      "3  ARUNACHAL PRADESH  \n",
      "4              ASSAM  \n",
      "Latitude         702\n",
      "Longitude        702\n",
      "Start Date         0\n",
      "Main Cause       122\n",
      "Area Affected    765\n",
      "Severity         765\n",
      "State            563\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Keep only columns needed for ML\n",
    "df_ml = df[\n",
    "    [\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\n",
    "        \"Start Date\",\n",
    "        \"Main Cause\",\n",
    "        \"Area Affected\",\n",
    "        \"Severity\",\n",
    "        \"State\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(df_ml.head())\n",
    "print(df_ml.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4572eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after drop: 262\n"
     ]
    }
   ],
   "source": [
    "df_ml = df_ml.dropna(subset=[\"Latitude\", \"Longitude\", \"Severity\"])\n",
    "print(\"Rows after drop:\", len(df_ml))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b110d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk_Level\n",
      "LOW       181\n",
      "HIGH       60\n",
      "MEDIUM     21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def make_risk(row):\n",
    "    if row[\"Severity\"] >= 3 or row[\"Area Affected\"] > 200000:\n",
    "        return \"HIGH\"\n",
    "    elif row[\"Severity\"] == 2:\n",
    "        return \"MEDIUM\"\n",
    "    else:\n",
    "        return \"LOW\"\n",
    "\n",
    "df_ml[\"Risk_Level\"] = df_ml.apply(make_risk, axis=1)\n",
    "print(df_ml[\"Risk_Level\"].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4534e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml[\"Area Affected\"] = df_ml[\"Area Affected\"].fillna(\n",
    "    df_ml[\"Area Affected\"].median()\n",
    ")\n",
    "\n",
    "df_ml[\"Main Cause\"] = df_ml[\"Main Cause\"].fillna(\"Unknown\")\n",
    "df_ml[\"State\"] = df_ml[\"State\"].fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec8a0987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Latitude  Longitude  Start Date        Main Cause  Area Affected  \\\n",
      "464   14.5398    75.0937  1985-06-23        Heavy rain      254234.60   \n",
      "465   32.8353    76.9103  1985-07-18        Heavy rain      117441.17   \n",
      "466   26.4816    82.8434  1985-09-13        Heavy rain       89994.67   \n",
      "467   21.1495    86.7154  1985-10-18  Tropical cyclone       46758.64   \n",
      "468   25.6339    84.0726  1986-06-15    Monsoonal rain      507167.44   \n",
      "\n",
      "     Severity    State Risk_Level  \n",
      "464       1.0  Unknown       HIGH  \n",
      "465       1.0  Unknown        LOW  \n",
      "466       2.0  Unknown     MEDIUM  \n",
      "467       2.0  Unknown     MEDIUM  \n",
      "468       1.0  Unknown       HIGH  \n",
      "Latitude         0\n",
      "Longitude        0\n",
      "Start Date       0\n",
      "Main Cause       0\n",
      "Area Affected    0\n",
      "Severity         0\n",
      "State            0\n",
      "Risk_Level       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_ml.head())\n",
    "print(df_ml.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf732f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Main Cause  Main Cause Enc\n",
      "464        Heavy rain               3\n",
      "465        Heavy rain               3\n",
      "466        Heavy rain               3\n",
      "467  Tropical cyclone               7\n",
      "468    Monsoonal rain               4\n",
      "    Risk_Level  Risk Enc\n",
      "464       HIGH         0\n",
      "465        LOW         1\n",
      "466     MEDIUM         2\n",
      "467     MEDIUM         2\n",
      "468       HIGH         0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_cause = LabelEncoder()\n",
    "le_state = LabelEncoder()\n",
    "le_risk = LabelEncoder()\n",
    "\n",
    "df_ml[\"Main Cause Enc\"] = le_cause.fit_transform(df_ml[\"Main Cause\"])\n",
    "df_ml[\"State Enc\"] = le_state.fit_transform(df_ml[\"State\"])\n",
    "df_ml[\"Risk Enc\"] = le_risk.fit_transform(df_ml[\"Risk_Level\"])\n",
    "\n",
    "print(df_ml[[\"Main Cause\", \"Main Cause Enc\"]].head())\n",
    "print(df_ml[[\"Risk_Level\", \"Risk Enc\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6741d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Month\n",
      "464    6.0\n",
      "465    7.0\n",
      "466    9.0\n",
      "467   10.0\n",
      "468    6.0\n"
     ]
    }
   ],
   "source": [
    "# Extract month from Start Date before it was dropped\n",
    "df[\"Start Date\"] = pd.to_datetime(df[\"Start Date\"], errors=\"coerce\")\n",
    "df[\"Month\"] = df[\"Start Date\"].dt.month\n",
    "\n",
    "# Now add the Month column to df_ml\n",
    "df_ml[\"Month\"] = df.loc[df_ml.index, \"Month\"]\n",
    "\n",
    "print(df_ml[[\"Month\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83e5f3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Latitude  Longitude  Month  Main Cause Enc  Area Affected  State Enc\n",
      "464   14.5398    75.0937    6.0               3      254234.60          0\n",
      "465   32.8353    76.9103    7.0               3      117441.17          0\n",
      "466   26.4816    82.8434    9.0               3       89994.67          0\n",
      "467   21.1495    86.7154   10.0               7       46758.64          0\n",
      "468   25.6339    84.0726    6.0               4      507167.44          0\n"
     ]
    }
   ],
   "source": [
    "X = df_ml[\n",
    "    [\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\n",
    "        \"Month\",\n",
    "        \"Main Cause Enc\",\n",
    "        \"Area Affected\",\n",
    "        \"State Enc\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "y_class = df_ml[\"Risk Enc\"]     # classification\n",
    "y_reg = df_ml[\"Severity\"]       # regression\n",
    "\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7178f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_class_train, y_class_test = train_test_split(\n",
    "    X, y_class, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "_, _, y_reg_train, y_reg_test = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53f8deb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.8867924528301887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.89      0.94      0.92        35\n",
      "           2       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.89        53\n",
      "   macro avg       0.63      0.65      0.64        53\n",
      "weighted avg       0.85      0.89      0.87        53\n",
      "\n",
      "[[14  0  0]\n",
      " [ 0 33  2]\n",
      " [ 0  4  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_class_train)\n",
    "\n",
    "y_class_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification Accuracy:\", accuracy_score(y_class_test, y_class_pred))\n",
    "print(classification_report(y_class_test, y_class_pred))\n",
    "print(confusion_matrix(y_class_test, y_class_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "723274bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.3167517399346283\n",
      "R2 Score: -0.18082096470381015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "reg = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "reg.fit(X_train, y_reg_train)\n",
    "\n",
    "y_reg_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_reg_test, y_reg_pred))\n",
    "print(\"R2 Score:\", r2_score(y_reg_test, y_reg_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90df89f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf, \"flood_risk_classifier.pkl\")\n",
    "joblib.dump(reg, \"flood_severity_regressor.pkl\")\n",
    "joblib.dump(le_risk, \"risk_encoder.pkl\")\n",
    "\n",
    "print(\"Models saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552655b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
